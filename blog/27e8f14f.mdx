---
authors:
- PuQing
date: 2023-11-22 22:02
keywords:
- 高斯分布
- 概率论
tags:
- 高斯分布
- 概率论
---
# 多元高斯分布

在 [高斯分布](./971deee9) 中我们分别介绍了一维高斯分布情况，以及对于多元高斯分布表达式中的 `马氏距离` 进行了解释。这一节将主要介绍在多元高斯分布的常用定理进行介绍。

## 多元高斯的线性性质

:::tip[]
已知：


<!--truncate-->
$$
\begin{split}
X\sim \mathcal{N}(\mu,\Sigma)\\
Y = AX+b
\end{split}
$$
那么可以得到：

$$
Y\sim \mathcal{N}(A\mu+b,A \Sigma A^\top)
$$
这里 $X \in \mathbb{R}^{p},A \in \mathbb{R}^{n \times p},Y \in\mathbb{R}^{n}$

:::
:::warning[ 证明]

:::
:::quote[ 这意味着什么？]
如果一个随机变量满足多元高斯分布，对这个随机变量做任意<Highlight>线性变换</Highlight>，得到的随机变量仍然满足多元高斯分布。

:::
## 高斯边缘分布与联合分布

本节探究两个问题？

:::quote[]

1. 如果一个分布是联合高斯分布，从中任取一些随机变量得到的分布是否是高斯分布？
2. 如果每一个随机变量的分布都是高斯分布，把他们组合在一起是否是联合高斯分布？

:::
### 从联合分布到边缘概率

从联合高斯分布到边缘高斯分布是成立的

::::danger[]
这句话的正常说法就是第一个问题

:::info
如果一个分布是联合高斯分布，从中任取一些随机变量得到的分布是否是高斯分布？


:::
::::
对于具有 $p$ 个随机变量的联合高斯分布或者说多元高斯分布，证明其边缘概率还是高斯分布。

证明：

$$
\begin{pmatrix}
X_{n_{1}} \\
\vdots \\
X_{n_{k}}
\end{pmatrix}=A\begin{pmatrix}
X_{1} \\
\vdots \\
X_{n}
\end{pmatrix}
$$
只要让第 $n_{1}$ 到 $n_{k}$ 个随机变量所在的位置是 $1$ 即可 (相当于选择出来了) ，根据上面的推论 [多元高斯的线性性质](#%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E7%9A%84%E7%BA%BF%E6%80%A7%E6%80%A7%E8%B4%A8) 可以得到，仍然为高斯分布。

### 从边缘分布到联合分布

但是反过来不一定成立。如果 $X_{1},\cdots,X_{n}$ 全部服从高斯分布，其 $X_{1},\cdots,X_{n}$ 的联合概率不一定是高斯分布。

$$
\begin{split}
X_{1}\sim \mathcal{N},X_{2}\sim \mathcal{N},\cdots,X_{n}\sim \mathcal{N}\\
\nRightarrow X=\left( X_{1}\cdots,X_{n} \right)^\top \sim \mathcal{N} 
\end{split}
$$
:::example[]
我们可以构造一个概率密度函数 $f(x,y)$，这个函数的边缘分布是高斯，但是联合分布不是高斯分布

函数主体是高斯的，但是边缘有波动

$$
f(x, y)=\frac{1}{2 \pi} \exp \left(-\frac{x^{2}+y^{2}}{2}\right)+g(x, y)
$$
我们希望这个 $g(x,y)$ 的边缘分布都是 $0$，即

$$
\int_{-\infty}^{+\infty} \mathrm{g}(\mathrm{x}, \mathrm{y}) \mathrm{dx}=\int_{-\infty}^{+\infty} \mathrm{g}(\mathrm{x}, \mathrm{y}) \mathrm{dy}=0
$$
如果我们增加这样一项

$$
g(x,y) = \sin x \sin y
$$
可是概率密度函数不能是负的，所以需要修正

$$
g(x,y) =1+ \sin x \sin y 
$$
因此，我们就可以得到一个例子

$$
\mathrm{f}(\mathrm{x}, \mathrm{y})=\frac{1}{2 \pi} \exp \left(-\frac{\mathrm{x}^{2}+\mathrm{y}^{2}}{2}\right)+(1+\sin \mathrm{x} \sin \mathrm{y})
$$
对 $x$ 和对 $y$ 的边缘分布都是高斯的，但是联合分布不是高斯分布

:::
### 联合高斯分布判据

:::quote[]
那么，什么样的判据才能推出联合高斯分布呢？

:::
对于一个随机变量向量 $X=(X_{1},\cdots,X_{n})^\top$ 是多元随机变量满足一下条件之一 [^1]

:::tip[]

1. 对于任意的线性组合 $Y=a_{1}X_{1}+\cdots+a_{n}X_{n}$ 是正态分布，写成向量乘的形式就是对于任意的常向量 $a \in \mathbb{R}^n$，随机变量 $Y=a^TX$ 是<Highlight>单变量高斯分布</Highlight>

:::
::::tip[]
2. 有一个 $\mu \in \mathbb{R}^n$ 的向量，以及一个对称、半正定的协方差矩阵 $\Sigma_{n \times n}$，使得 $X=(X_{1},\cdots,X_{n})$ 的 [特征函数(This page is not published)](./404) 等于：

$$
\rho_{X}(\omega) = \exp \left( i \omega^T\mu-\frac{1}{2}\omega^T \Sigma \omega \right) 
$$
.

:::warning[ 证明]

:::
::::
## 高斯分布的相关性与独立性

### 独立性和相关性

::::note[]
所谓两个随机变量不相关，就是两个随机变量的期望，等于其各自的期望的乘积

$$
\mathbb{E}\left[ XY \right]  = \mathbb{E}\left[ X \right] \mathbb{E}\left[ Y \right]
$$
.

:::tip[]
而 `相关` 实际上就是线性相关，也就是协方差或者 `Pearson` 的相关系数为 $0$

$$
Cov\left[ X,Y \right]  = \mathbb{E}\left[ XY \right] -\mathbb{E}\left[ X \right] \mathbb{E}\left[ Y \right]=0
$$
:::
::::
而两个随机变量独立，是他们的联合分布等于各自概率密度的乘积

$$
f_{XY}(x,y) = f_{X}(x)f_{Y}(y)
$$
:::info
独立一定不相关，但是不相关不一定独立。独立要求更高


:::
:::warning[]
这可能过于抽象，下面举个例子

![Untitled.bmp](https://images.puqing.work/2023/11/24/6560b9cd1e055.bmp)

随机变量 $(X,Y)$ 均匀分布在单位圆 $x^{2}+y^{2}=1$ 上

但是 $X$ 和 $Y$ 的 (线性) 相关系数是 $0$，直观的来说，因为是一个圆，用一个线性的线描述都是不合适的，因为是对称的。数学上：

$$
\mathbb{E}\left[ X\mid Y \right] =\mathbb{E}\left[ Y\mid X \right]=0
$$
所以

$$
\mathbb{E}\left[ X \right] = \mathbb{E}\left[ Y \right] =0
$$
并且

$$
\mathbb{E}\left[ XY \right] = \mathbb{E}\left[ \mathbb{E}\left[ XY\mid X \right] \right] = \mathbb{E}\left[X \mathbb{E}\left[ Y\mid X \right] \right]=0
$$
所以

$$
Cov\left[ X,Y \right] =\mathbb{E}\left[ XY \right] -\mathbb{E}\left[ X \right] \mathbb{E}\left[ Y \right]=0
$$
但是显然，$X,Y$ 不是独立的。因为 $X$ 的取值对 $Y$ 是有影响的，反之亦然。

$$
y= \pm \sqrt{ 1-x^2 }
$$
:::
### 高斯分布的不相关和独立

:::quote[]
如果两个高斯分布是不相关的，能够得到二者独立吗?

:::
也是不行的

:::warning[ 证明]

:::
### 联合高斯分布的不相关和独立

当两个随机变量是联合高斯分布的时候，二者如果不相关，则一定独立

$$
\begin{cases}
\text { Joint Gaussian } \\
\text { Uncorrelated }
\end{cases}\Rightarrow \text { independent }
$$
:::warning[ 证明]

:::
## 高斯条件分布

### 条件高斯分布的计算

假设 $X$ 符合联合高斯分布，并且可以分成 $X_{a}$ 和 $X_{b}$ 两个联合分布，则 $X$ 可以表示成

$$
X=\begin{pmatrix}
X_{a} \\
X_{b}
\end{pmatrix}_{p}\begin{matrix}
\rightarrow  m \\
\rightarrow  n
\end{matrix}
\quad 
m+n=p 
\quad 
\mu=\begin{pmatrix}
\mu_{a} \\
\mu_{b}
\end{pmatrix}
\quad \Sigma=\begin{pmatrix}
\Sigma_{a a} & \Sigma_{a b} \\
\Sigma_{b a} & \Sigma_{b b}
\end{pmatrix}
$$
$$
X\sim \mathcal{N}\left( \mu,\Sigma \right) 
$$
由条件概率公式可知：

$$
p(X_{a},X_{b}) = p(X_{b})p(X_{a}\mid X_{b})
$$
下面分别求得 $p(X_{b}),p(X_{a}\mid X_{b})$

#### 求解边缘概率密度

可以将 $X_{a}$ 写为：

$$
X_{b}=
\underbrace{\begin{pmatrix}
\mathbb{O}_{m \times m} & \mathbb{I}_{n \times n}
\end{pmatrix}}_{{\color{Red} A} }
\begin{pmatrix}
X_{a} \\
X_{b}
\end{pmatrix}
$$
于是：

$$
\mathbb{E}\left[ X_{b} \right] =  
\begin{pmatrix}
\mathbb{O}_{m \times m} & \mathbb{I}_{n \times n}
\end{pmatrix}\begin{pmatrix}
\mu_{a} \\
\mu_{b}
\end{pmatrix}=\mu_{b}
$$
而

$$
Var\left[ X_{b} \right] = \begin{pmatrix}
\mathbb{O}_{m \times m} & \mathbb{I}_{n \times n}
\end{pmatrix}\begin{pmatrix}
\Sigma_{aa} & \Sigma_{ab} \\
\Sigma_{ba} & \Sigma_{bb}
\end{pmatrix}\begin{pmatrix}
\mathbb{O}_{m \times m}  \\
\mathbb{I}_{n \times n}
\end{pmatrix} = 
\Sigma_{bb}
$$
所以，$X_{b}\sim \mathcal{N}\left( \mu_{b},\Sigma_{bb} \right)$

:::info
这是符合前文的推导的


:::
#### 求解条件概率密度

对于条件概率有：

$$
p(X_{a}\mid X_{b}) = \frac{p_{X}(X_{a}X_{b})}{p(X_{b})}
$$
即对 $X_{b}$ 的条件概率等于 $X_{a},X_{b}$ 的联合分布除以 $X_{a}$ 的边缘概率。

由于联合高斯分布中取出来一部分还是高斯分布，所以上面是高斯，下面还是高斯。最终得到的还是一个高斯分布。

$$
\frac{p_{X}(X_{a}X_{b})}{p(X_{b})} = \frac{c_{1}\exp \left( -\frac{1}{2} \left( X_{a}^T-\mu_{a}^T,X_{b}^T-\mu_{b}^T \right)\Sigma^{-1}\left( X_{a}-\mu_{a}, X_{b}-\mu_{b}\right)   \right)}{c_{2}\exp \left( -\frac{1}{2} \left( X_{b}^T-\mu_{b}^T\right)\Sigma_{bb}^{-1}\left( X_{b}-\mu_{b}\right)   \right)} 
$$
其中

$$
\Sigma=\begin{pmatrix}
\Sigma_{a a} & \Sigma_{a b} \\
\Sigma_{b a} & \Sigma_{b b}
\end{pmatrix}
$$
指数相除部分可以转化为加减，所以指数部分可以写为：

$$
-\frac{1}{2} \left( X_{a}^T-\mu_{a}^T,X_{b}^T-\mu_{b}^T \right)\Sigma^{-1}\left( X_{a}-\mu_{a}, X_{b}-\mu_{b}\right)+\frac{1}{2}\left( X_{b}^T-\mu_{b}^T \right) \Sigma_{bb}^{-1}\left( X_{b}-\mu_{b} \right)  
$$
上式我们写成矩阵形式

$$
\begin{split}
&-\frac{1}{2}\left\{ \left( \begin{bmatrix}
X_{a} \\
X_{b}
\end{bmatrix}-\begin{bmatrix}
\mu_{a} \\
\mu_{b}
\end{bmatrix} \right)^\mathrm{T}
\begin{bmatrix}
\Sigma_{aa} & \Sigma_{ab} \\
\Sigma_{ba} & \Sigma_{bb}
\end{bmatrix}^{-1}
\left( \begin{bmatrix}
X_{a} \\
X_{b}
\end{bmatrix}-\begin{bmatrix}
\mu_{a} \\
\mu_{b}
\end{bmatrix} \right) -
\left( X_{b}-\mu_{b} \right) ^\mathrm{T}
\Sigma_{bb}^{-1}\left( X_{b}-\mu_{b} \right) 
\right\} \\
=&-\frac{1}{2}
\left\{ 
\begin{bmatrix}
X_{a}-\mu_{a} \\
X_{b}-\mu_{b}
\end{bmatrix}^\mathrm{T}
\begin{bmatrix}
\Sigma_{aa} & \Sigma_{ab} \\
\Sigma_{ba} & \Sigma_{bb}
\end{bmatrix}^{-1}
\begin{bmatrix}
X_{a}-\mu_{a} \\
X_{b}-\mu_{b}
\end{bmatrix}-
\left( X_{b}-\mu_{b} \right) ^\mathrm{T}
\Sigma_{bb}^{-1}\left( X_{b}-\mu_{b} \right) 
\right\} \\
=&-\frac{1}{2}
\left\{ 
\begin{bmatrix}
X_{a}-\mu_{a} \\
X_{b}-\mu_{b}
\end{bmatrix}^\mathrm{T}
\begin{bmatrix}
I & 0 \\
-\Sigma_{bb}^{-1} \Sigma_{ba} & I
\end{bmatrix}
\begin{bmatrix}
\Sigma_{aa}-\Sigma_{ab}\Sigma_{bb}^{-1}\Sigma_{ba} & 0 \\
0 & \Sigma_{bb}
\end{bmatrix}
\begin{bmatrix}
I & -\Sigma_{ab}\Sigma_{bb}^{-1} \\
0 & I
\end{bmatrix}
\begin{bmatrix}
X_{a}-\mu_{a} \\
X_{b}-\mu_{b}
\end{bmatrix}-
\left( X_{b}-\mu_{b} \right) ^\mathrm{T}
\Sigma_{bb}^{-1}\left( X_{b}-\mu_{b} \right) 
\right\} \\
\end{split}
$$
:::warning[]
这里最后一步的变换就是在 [Schur complement](./67d6eeea) 中提到的舒尔补求矩阵逆方法

:::
这里有 $ABCDE$ 矩阵连乘，我们转换成 $(AB)C(DE)$，同时令 $\tilde{k}=k-\mu_k$

于是上式等于：

$$
\begin{split}
\Phi &= -\frac{1}{2}\left\{ 
\begin{bmatrix}
\tilde{X}_{a} - \tilde{X}_{b}\Sigma_{bb}^{-1}\Sigma_{ba} \\
\tilde{X}_{b}
\end{bmatrix}^\mathrm{T}
\begin{bmatrix}
\Sigma_{aa}-\Sigma_{ab}\Sigma_{bb}^{-1}\Sigma_{ba} & 0 \\
0 & \Sigma_{bb}
\end{bmatrix}
\begin{bmatrix}
\tilde{X}_{a}-\Sigma_{ab}\Sigma_{bb}^{-1}\tilde{X}_{b} \\
\tilde{X}_{b}
\end{bmatrix}-\left( 
\tilde{X}_{b}^\mathrm{T}\Sigma_{bb}\tilde{X}_{b}
\right) 
\right\} \\
&=-\frac{1}{2}\left\{ 
\begin{bmatrix}
\tilde{X}_{a} - \tilde{X}_{b}\Sigma_{bb}^{-1}\Sigma_{ba}
\end{bmatrix}^\mathrm{T}
\left( 
\Sigma_{aa}-\Sigma_{ab}\Sigma _{bb}^{-1}\Sigma_{ba}
\right) 
\begin{bmatrix}
\tilde{X}_{a}-\Sigma_{ab}\Sigma_{bb}^{-1}\tilde{X}_{b}
\end{bmatrix}
\right\} 
\end{split}
$$
所以很容易看出当前的 $p(X_{a}\mid X_{b})$ 服从 $\mathcal{N}(\mu_{a\mid b},\Sigma_{a\mid b})$ 分布：

$$
\begin{split}
\mu_{a\mid b} = \mu_{a}+\Sigma_{ab}\Sigma_{bb}^{-1}(X_{b}-\mu_{b})\\
\Sigma_{a\mid b} = \Sigma_{aa}-\Sigma_{ab}\Sigma_{bb}^{-1}\Sigma_{ba}
\end{split}
$$
:::tip[]
可以看到的是其方差就等于 $\Sigma$ 对于 $\Sigma_{aa}$ 的舒尔补

:::
## 求解线性模型

:::danger[]
已知：$p(x)=\mathcal{N}\left(\mu, \Lambda^{-1}\right), p(y \mid x)=\mathcal{N}\left(A x+b, L^{-1}\right)$，求解：$p(y),p(x\mid y)$

:::
根据上文提到的 [多元高斯的线性性质](#%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E7%9A%84%E7%BA%BF%E6%80%A7%E6%80%A7%E8%B4%A8) ，我们可以设

$$
y=Ax+b+\epsilon
$$
其中 $\epsilon \sim \mathcal{N}(0,L^{-1})$

于是有边缘概率：

$$
\begin{split}
&\mathbb{E}\left[ y \right] =\mathbb{E}\left[ Ax+b+\epsilon \right]  =\mathbb{E}\left[ Ax+b \right]  +\mathbb{E}\left[ \epsilon \right] = A\mu+b  \\
&Var\left[ y \right]  = Var\left[ Ax+b+\epsilon \right] =Var\left[ Ax \right]+Var\left[ \epsilon \right] = A \Lambda ^{-1}A^{\mathrm{T}}+L^{-1}
\end{split}
$$
于是有 $p(y) \sim \mathcal{N}(A\mu+b,A \Lambda ^{-1}A^{\mathrm{T}}+L^{-1})$

对于条件概率，我们有：

$$
p(y\mid x) = \frac{p(x,y)}{p(x)}
$$
这样我们就能和上面推导的 [求解条件概率密度](#%E6%B1%82%E8%A7%A3%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6) 联系上

这里我们假设 $x$ 与 $y$ 的协方差为 $\Delta$，于是协方差矩阵可以写为：

$$
z = \begin{pmatrix}
x \\
y
\end{pmatrix}
\sim 
\mathcal{N}\left( 
\begin{pmatrix}
\mu \\
A\mu+b
\end{pmatrix},
\begin{pmatrix}
\Lambda ^{-1} & \Delta \\
\Delta & A \Lambda ^{-1}A^{\mathrm{T}}+L^{-1}
\end{pmatrix}
\right) 
$$
其中的 $\Delta$ 是多少，我们并不知道，需要求解。

:::quote[ 求解 $\Delta$]
直接使用协方差的定义进行求解

$$
\begin{split}
\Delta & =\operatorname{Cov}(x, y)=\mathbb{E}\left[(x-\mathbb{E}[x])(y-\mathbb{E}[y])^{T}\right] \\
& =\mathbb{E}\left[(x-\mu)(y-(A \mu+b))^{T}\right] \\
& =\mathbb{E}\left[(x-\mu)(A x+\epsilon-A \mu)^{T}\right] \\
& =\mathbb{E}\left[(x-\mu)(A x-A \mu+\epsilon)^{T}\right] \\
& =\mathbb{E}\left[(x-\mu)(A x-A \mu)^{T}+(x-\mu) \epsilon^{T}\right] \\
& =\mathbb{E}\left[(x-\mu)(A x-A \mu)^{T}\right]+\mathbb{E}\left[(x-\mu) \epsilon^{T}\right]
\end{split}
$$
而由于 $x-\mu$ 和 $\epsilon$ 之间是独立的，那么 $\mathbb{E}\left[ (x-\mu)\epsilon^{\mathbf{T}} \right]=\mathbb{E}\left[ (x-\mu) \right]\mathbb{E}\left[ \epsilon^{\mathbf{T}} \right]=0$，所以我们有：

$$
\begin{split}
\Delta & = \mathbb{E}\left[ (x-\mu)(Ax-A\mu)^{\mathbf{T}} \right] \\
& =\mathbb{E}\left[ (x-\mu)(x-\mu)^{\mathbf{T}} \right]\cdot A^{\mathbf{T}} \\
& =Var\left[ x\right] \cdot A^{\mathbf{T}}\\
& =\Lambda ^{-1}A^{\mathbf{T}}
\end{split}
$$
:::
所以，$x$ 和 $y$ 之间的联合概率分布可表达为

$$
z=\begin{pmatrix}
x \\
y
\end{pmatrix} \sim \mathcal{N}\left( 
\begin{pmatrix}
\mu \\
A \mu+b
\end{pmatrix},
\begin{pmatrix}
\Lambda^{-1} & \Lambda^{-1} A^{T} \\
\Lambda^{-1} A^{T} & A \Lambda^{-1} A^{T}+L^{-1}
\end{pmatrix}
\right)
$$
利用上面推导的公式，可以得到 $p(x\mid y)$。结果如下：

$$
\begin{array}{c}
\mathbb{E}[x \mid y]=\mu+\Lambda^{-1} A^{T}\left(L^{-1}+A \Lambda^{-1} A^{T}\right)^{-1}(y-A \mu-b) \\
\operatorname{Var}[x \mid y]=\Lambda^{-1}-\Lambda^{-1} A^{T}\left(L^{-1}+A \Lambda^{-1} A^{T}\right)^{-1} A \Lambda^{-1}
\end{array}
$$
:::info
之后可能有单独的一章说 [线性高斯模型(This page is not published)](./404)


:::
## 相关资料

- [Marginalization & Schur Complement 边缘化与舒尔补 - 知乎](https://zhuanlan.zhihu.com/p/363975790)
- [多元高斯分布完全解析 - 知乎](https://zhuanlan.zhihu.com/p/58987388)
- [为什么随机变量X和Y不相关却不一定独立？ - 知乎](https://www.zhihu.com/question/26583332)
- [【随机过程】8 - 多元高斯分布及其线性性质_multivariable gaussian distribution linear transfo_Ciaran-byte的博客-CSDN博客](https://blog.csdn.net/qq_41741344/article/details/121728111)

[^1]:[Multivariate normal distribution - Wikipedia](https://en.wikipedia.org/w/index.php?title=Multivariate_normal_distribution&oldid=950141067)
